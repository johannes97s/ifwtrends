value = last_values) %>%
mutate(time = floor_date(time, "quarter")) %>%
rename(index = value)
last_model = last(models)
return(list(forec = forec,             #returns forcasted values and
last_model = last_model))     #model estimated with contemporary data
}
forecast_q(r_list2, dat, fd = F)$forec %>%
left_join(dat, by = "time") %>%
pivot_longer(cols = -time, names_to = "id", values_to = "value") %>%
ggplot(aes(x=  time, y = value, color = id)) +
geom_line()
dat <- vdax %>%
mutate(value = c(0, diff(log(value),1)) )
forecast_q(r_list2, dat, fd = F)$forec %>%
left_join(dat, by = "time") %>%
pivot_longer(cols = -time, names_to = "id", values_to = "value") %>%
ggplot(aes(x=  time, y = value, color = id)) +
geom_line()
forecast_q(r_list2, dat, fd = T)$forec %>%
left_join(dat, by = "time") %>%
pivot_longer(cols = -time, names_to = "id", values_to = "value") %>%
ggplot(aes(x=  time, y = value, color = id)) +
geom_line()
forecast_q <- function(r_list, dat, fd = T){
r_raw <- r_list[1:length(r_list) %% 3 == 0]
r_raw <- lapply(r_raw, function(x){
mutate(x, time = floor_date(time, "quarter")) %>% #aggregate GT Data to quarter
group_by(time) %>%                              #
transmute_at(.vars = vars(-time), .funs =  mean) %>%  #
ungroup() %>%
unique()
})
if (fd) r_raw <- lapply(r_raw, function(x) mutate(x, time = time, #first differences if fd=T set
across(.cols = -1, function(y) c(0, diff(y,1))),
.keep = "used"))
r_raw <- lapply(r_raw, function(x){
left_join(x, dat[1:nrow(x), ], by = "time") %>%
select(time, dat = value, everything()) %>%
filter(time != as.Date("2011-01-01")) %>% #omit structural breaks
filter(time != as.Date("2016-01-01")) %>%
mutate(across(everything(), function(y) replace(y, y == -Inf, NA_real_))) %>%
mutate(across(everything(), function(y) replace(y, y == Inf, NA_real_)))
})
# use PCA
# r_factors <- lapply(r_raw, function(x){
#   pc <- as_tibble(prcomp(x[-c(1,2)])$x)
#   bind_cols(x[c(1,2)], pc[,1:min(20, length(r_raw[[1]])-2)]) %>% #number of PCs
#     drop_na()
# })
r <- r_raw #set r <- r_factors to use PCA-Model
build_model <- function(series){ #Function to estimate the model
y <- as.matrix(series[2])
x <- as.matrix(series[-c(1,2)])
cv <- cv.glmnet(x, y, alpha = 0)
model <- glmnet(x, y, alpha = 0, lambda = cv$lambda.min) #alpha = 1 LASSO
model                                                    #lambda= 0 OLS
}
covariats <- lapply(r, function(x) as.matrix(x[-c(1,2)])) #Trends Data to forecast with
#previous estimated model
models <- lapply(lag(r)[-1], function(x) build_model(x))           #estimate model
pred_values <- mapply(predict, models, covariats[-c(1)]) #forecast
last_values <- sapply(pred_values, last) #select last value in each vintage as forecast
#for relevant quarter
forec <- tibble(time = seq.Date(max(first(r)$time)+months(3), max(last(r)$time), by ="quarter"),
value = last_values) %>%
mutate(time = floor_date(time, "quarter")) %>%
rename(index = value)
last_model = last(models)
return(list(forec = forec,             #returns forcasted values and
last_model = last_model))     #model estimated with contemporary data
}
dat <- vdax %>%
mutate(value = c(0, diff(log(value),1)) )
forecast_q(r_list2, dat, fd = T)$forec %>%
left_join(dat, by = "time") %>%
pivot_longer(cols = -time, names_to = "id", values_to = "value") %>%
ggplot(aes(x=  time, y = value, color = id)) +
geom_line()
forecast_q <- function(r_list, dat, fd = T){
r_raw <- r_list[1:length(r_list) %% 3 == 0]
r_raw <- lapply(r_raw, function(x){
mutate(x, time = floor_date(time, "quarter")) %>% #aggregate GT Data to quarter
group_by(time) %>%                              #
transmute_at(.vars = vars(-time), .funs =  mean) %>%  #
ungroup() %>%
unique()
})
if (fd) r_raw <- lapply(r_raw, function(x) mutate(x, time = time, #first differences if fd=T set
across(.cols = -1, function(y) c(0, diff(y,1))),
.keep = "used"))
r_raw <- lapply(r_raw, function(x){
left_join(x, dat[1:nrow(x), ], by = "time") %>%
select(time, dat = value, everything()) %>%
filter(time != as.Date("2011-01-01")) %>% #omit structural breaks
filter(time != as.Date("2016-01-01")) %>%
mutate(across(everything(), function(y) replace(y, y == -Inf, NA_real_))) %>%
mutate(across(everything(), function(y) replace(y, y == Inf, NA_real_)))
})
# use PCA
# r_factors <- lapply(r_raw, function(x){
#   pc <- as_tibble(prcomp(x[-c(1,2)])$x)
#   bind_cols(x[c(1,2)], pc[,1:min(20, length(r_raw[[1]])-2)]) %>% #number of PCs
#     drop_na()
# })
r <- r_raw #set r <- r_factors to use PCA-Model
build_model <- function(series){ #Function to estimate the model
y <- as.matrix(series[2])
x <- as.matrix(series[-c(1,2)])
cv <- cv.glmnet(x, y, alpha = 0)
model <- glmnet(x, y, alpha = 0, lambda = 0)#cv$lambda.min) #alpha = 1 LASSO
model                                                    #lambda= 0 OLS
}
covariats <- lapply(r, function(x) as.matrix(x[-c(1,2)])) #Trends Data to forecast with
#previous estimated model
models <- lapply(lag(r)[-1], function(x) build_model(x))           #estimate model
pred_values <- mapply(predict, models, covariats[-c(1)]) #forecast
last_values <- sapply(pred_values, last) #select last value in each vintage as forecast
#for relevant quarter
forec <- tibble(time = seq.Date(max(first(r)$time)+months(3), max(last(r)$time), by ="quarter"),
value = last_values) %>%
mutate(time = floor_date(time, "quarter")) %>%
rename(index = value)
last_model = last(models)
return(list(forec = forec,             #returns forcasted values and
last_model = last_model))     #model estimated with contemporary data
}
forecast_q(r_list2, dat, fd = T)$forec %>%
left_join(dat, by = "time") %>%
pivot_longer(cols = -time, names_to = "id", values_to = "value") %>%
ggplot(aes(x=  time, y = value, color = id)) +
geom_line()
r_list2 <- r_list[1:45]
vdax <- readxl::read_xlsx("data/service_imports.xlsx") %>%
transmute(time = floor_date(as.Date(Name), "quarter"), value = as.numeric(`BD IMPORTS - SERVICES CONA`))
dat <- vdax %>%
mutate(value = c(0, diff(log(value),1)) )
forecast_q(r_list2, dat, fd = T)$forec %>%
left_join(dat, by = "time") %>%
pivot_longer(cols = -time, names_to = "id", values_to = "value") %>%
ggplot(aes(x=  time, y = value, color = id)) +
geom_line()
library(knitr)
library(dplyr)
library(tibble)
library(ggplot2)
library(stringr)
r_list <- readRDS("data/travel.rds")
view(r_list)
r_list <- readRDS("data/travel.rds")
r_list <- readRDS("data/travel.rds")
view(r_list)
view(r_list[[1]])
dat <- vdax %>%
mutate(value = c(0, value/lag(value) - 1) )
dat <- vdax %>%
mutate(value = value/lag(value) - 1) )
dat <- vdax %>%
mutate(value = value/lag(value) - 1)
forecast_q(r_list, dat, fd = T)$forec %>%
left_join(dat, by = "time") %>%
pivot_longer(cols = -time, names_to = "id", values_to = "value") %>%
ggplot(aes(x=  time, y = value, color = id)) +
geom_line()
view(dat)
dat[1,2] <- 0
dat <- imports %>%
mutate(value = value/lag(value) - 1)
imports <- readxl::read_xlsx("data/service_imports.xlsx") %>%
transmute(time = floor_date(as.Date(Name), "quarter"), value = as.numeric(`BD IMPORTS - SERVICES CONA`))
dat <- imports %>%
mutate(value = value/lag(value) - 1)
dat[1,2] <- 0
forecast_q(r_list, dat, fd = T)$forec %>%
left_join(dat, by = "time") %>%
pivot_longer(cols = -time, names_to = "id", values_to = "value") %>%
ggplot(aes(x=  time, y = value, color = id)) +
geom_line()
gtrends::categories
gtrendsR::categories
filter(gtrendsR::categories, id %in% c(203, 206, 179, 1003, 1004, 208, 1010, 1011))
r_list <- readRDS("data/anxiety.rds")
r_list <- r_list[1:45]
vdax<- readxl::read_xlsx("data/service_imports.xlsx") %>%
transmute(time = floor_date(as.Date(Name), "quarter"), value = as.numeric(`BD IMPORTS - SERVICES CONA`))
dat <- vdax %>%
mutate(value = value/lag(value) - 1)
dat <- vdax %>%
mutate(value = value/lag(value) - 1)
dat[1,2] <- 0
forecast_m(r_list, dat, fd = T)$forec %>%
left_join(dat, by = "time") %>%
pivot_longer(cols = -time, names_to = "id", values_to = "value") %>%
ggplot(aes(x=  time, y = value, color = id)) +
geom_line()
dat
dat <- vdax %>%
mutate(value = value/lag(value) - 1)
forecast_m(r_list, dat, fd = T)$forec %>%
left_join(dat, by = "time") %>%
pivot_longer(cols = -time, names_to = "id", values_to = "value") %>%
ggplot(aes(x=  time, y = value, color = id)) +
geom_line()
r_list <- readRDS("data/anxiety.rds")
r_list <- r_list[1:45]
tail(last(r_list))
tail(dat)
vdax<- readxl::read_xlsx("data/vdax.xlsx") %>%
transmute(time = floor_date(as.Date(Name), "quarter"), value = as.numeric(`BD IMPORTS - SERVICES CONA`))
names(readxl::read_xlsx("data/vdax.xlsx"))
vdax<- readxl::read_xlsx("data/vdax.xlsx") %>%
transmute(time = floor_date(as.Date(Name), "quarter"), value = as.numeric(`VDAX-NEW VOLATILITY INDEX - PRICE INDEX`))
tail(dat)
vdax<- readxl::read_xlsx("data/vdax.xlsx") %>%
transmute(time = floor_date(as.Date(Name), "month"), value = as.numeric(`VDAX-NEW VOLATILITY INDEX - PRICE INDEX`))
tail(dat)
vdax<- readxl::read_xlsx("data/vdax.xlsx") %>%
transmute(time = floor_date(as.Date(Name), "month"), value = as.numeric(`VDAX-NEW VOLATILITY INDEX - PRICE INDEX`))
dat <- vdax %>%
mutate(value = value/lag(value) - 1)
tail(dat)
tail(last(r_list))
r_list <- readRDS("data/anxiety.rds")
tail(last(r_list))
r_list <- readRDS("data/anxiety.rds")
vdax<- readxl::read_xlsx("data/vdax.xlsx") %>%
transmute(time = floor_date(as.Date(Name), "month"), value = as.numeric(`VDAX-NEW VOLATILITY INDEX - PRICE INDEX`))
dat <- vdax %>%
mutate(value = value/lag(value) - 1)
forecast_m(r_list, dat, fd = T)$forec %>%
left_join(dat, by = "time") %>%
pivot_longer(cols = -time, names_to = "id", values_to = "value") %>%
ggplot(aes(x=  time, y = value, color = id)) +
geom_line()
first(r_list)
dat
dat <- vdax %>%
mutate(value = value/lag(value) - 1) %>%
filter(time >= min(first(r_list)$time))
r_list <- readRDS("data/anxiety.rds")
vdax<- readxl::read_xlsx("data/vdax.xlsx") %>%
transmute(time = floor_date(as.Date(Name), "month"), value = as.numeric(`VDAX-NEW VOLATILITY INDEX - PRICE INDEX`))
dat <- vdax %>%
mutate(value = value/lag(value) - 1) %>%
filter(time >= min(first(r_list)$time))
dat
forecast_m(r_list, dat, fd = T)$forec %>%
left_join(dat, by = "time") %>%
pivot_longer(cols = -time, names_to = "id", values_to = "value") %>%
ggplot(aes(x=  time, y = value, color = id)) +
geom_line()
dat <- vdax %>%
mutate(value = value/lag(value) - 1) %>%
filter(time >= min(first(r_list)$time))
forecast_m(r_list, dat, fd = F)$forec %>%
left_join(dat, by = "time") %>%
pivot_longer(cols = -time, names_to = "id", values_to = "value") %>%
ggplot(aes(x=  time, y = value, color = id)) +
geom_line()
dat <- vdax %>%
#mutate(value = value/lag(value) - 1) %>%
filter(time >= min(first(r_list)$time))
forecast_m(r_list, dat, fd = F)$forec %>%
left_join(dat, by = "time") %>%
pivot_longer(cols = -time, names_to = "id", values_to = "value") %>%
ggplot(aes(x=  time, y = value, color = id)) +
geom_line()
markdown::renderMarkdown("vignettes/ifwtrends-intro.Rmd")
rmarkdown::render("vignettes/ifwtrends-intro.Rmd")
#' @importFrom gtrendsR gtrends
#' @importFrom tidyr pivot_longer
#' @importFrom tidyr pivot_wider
#' @importFrom stats prcomp
#' @importFrom tidyselect any_of
#' @importFrom tsbox ts_ts
#' @importFrom lubridate as_date
#' @importFrom stringr str_c
#' @importFrom stringr str_sub
#' @export
pca <- function(keywords = NA,
categories = 0,
geo = "DE",
time = str_c("2006-01-01 ", Sys.Date())) {
start <- str_sub(time, 1, 10)
end <- str_sub(time, 12, 21)
stopifnot("Either choose keywords or categories! Leave the other argument empty" = is.na(keywords) | categories == 0)
# Check if function is used on the first day of the month
day <- format(end, format = "%d")
if (day == "01") {
# If indeed it is the first day of the month,
# we need to shorten the dates vector by one month because
# gtrends data don't include the first day of the month if that's today.
end <- seq(end, length = 2, by = "-1 months")[2]
}
dates <- seq.Date(as.Date(start), as.Date(end), by = "month")
dat <- tibble::tibble()
for (kw in keywords) {
for (cat in categories) {
temp <-
tibble::as_tibble(gtrends(
keyword = kw,
category = cat,
geo = geo,
time = "all"
)$interest_over_time)
if (nrow(temp) == 0) {
stop(str_c("Keine Daten fuer Kategorie ", cat))
}
if ("keyword" %in% names(temp)) {
temp <- select(temp, -category)
}
temp <- temp %>%
mutate(date = as_date(date)) %>%
select(date, key = any_of(c("keyword", "category")), value = hits) %>%
filter(date %in% dates)
dat <- bind_rows(dat, temp)
}
}
pc <- bind_cols(date = dates, as_tibble(prcomp(ts_ts(dat))$x))
dat <- select(pivot_wider(dat, names_from = key, values_from = value), -date)
result <- bind_cols(pc, dat)
return(result)
}
#' @examples \dontrun{
#' daily_series(keyword = "Ikea", geo = "NL", from = "2021-01-01")
#' }
#' @import trendecon tsbox lubridate zoo tibble tempdisagg magrittr
#' @importFrom dplyr select
#' @importFrom dplyr mutate
#' @importFrom dplyr filter
#' @importFrom gtrendsR gtrends
#' @importFrom stats time
#' @export
daily_series <- function(keyword = c("arbeitslos"),
geo = "DE",
from = "2006-01-01") {
from <- as.Date(from)
n1 <- as.numeric((Sys.Date() - from - 180) / 15) + 50
ifelse(n1 > 0, n1 <- n1, n1 <- 4) # set n1 if negativ
d <- trendecon:::ts_gtrends_windows(
keyword = keyword,
geo = geo,
from = from,
stepsize = "15 days", windowsize = "6 months",
n_windows = n1, wait = 20, retry = 10, # n_windows calculated such that it reaches up to current date
prevent_window_shrinkage = TRUE
)
d2 <- trendecon:::ts_gtrends_windows(
keyword = keyword,
geo = geo,
from = seq(Sys.Date(), length.out = 2, by = "-90 days")[2], # Heute -90 Tage
stepsize = "1 day", windowsize = "3 months",
n_windows = 12, wait = 20, retry = 10,
prevent_window_shrinkage = FALSE
)
dd <- trendecon:::aggregate_averages(trendecon:::aggregate_windows(d), trendecon:::aggregate_windows(d2))
# download weekly series
n2 <- as.numeric((Sys.Date() - from - 5 * 365) / (11 * 7)) + 10
ifelse(n2 > 0, n2 <- n2, n2 <- 4)
w <- trendecon:::ts_gtrends_windows(
keyword = keyword,
geo = geo,
from = from,
stepsize = "11 weeks", windowsize = "5 years",
n_windows = n2, wait = 20, retry = 10,
prevent_window_shrinkage = TRUE
)
w2 <- trendecon:::ts_gtrends_windows(
keyword = keyword,
geo = geo,
from = seq(Sys.Date(), length.out = 2, by = "-1 year")[2],
stepsize = "1 week", windowsize = "1 year",
n_windows = 12, wait = 20, retry = 10,
prevent_window_shrinkage = FALSE
)
ww <- trendecon:::aggregate_averages(trendecon:::aggregate_windows(w), trendecon:::aggregate_windows(w2))
# download monthly series
n3 <- as.numeric(Sys.Date() - from - 15 * 365) / (30) + 12
ifelse(n3 > 0, n3 <- n3, n3 <- 4)
m <- trendecon:::ts_gtrends_windows(
keyword = keyword,
geo = geo,
from = from,
stepsize = "1 month", windowsize = "15 years",
n_windows = n3, wait = 20, retry = 10,
prevent_window_shrinkage = FALSE
)
m2 <- trendecon:::ts_gtrends_windows(
keyword = keyword,
geo = geo,
from = from,
stepsize = "1 month", windowsize = "20 years", ### Hier evtl aufpassen, geht nur bis 2026!
n_windows = 1, wait = 20, retry = 10,
prevent_window_shrinkage = FALSE
)
mm <- trendecon:::aggregate_averages(trendecon:::aggregate_windows(m), trendecon:::aggregate_windows(m2))
dd <- select(dd, -n)
ww <- select(ww, -n)
mm <- select(mm, -n)
ww %>%
mutate(week = lubridate::week(time), year = lubridate::year(time)) %>%
filter(week <= 52) %>%
select(time, value) -> ww
dd <- ts_regular(ts_dts(dd))
dd$value <- 0.5 * (na.locf(dd$value, fromLast = TRUE) + na.locf(dd$value))
ww <- ts_regular(ts_dts(ww))
ww$value <- 0.5 * (na.locf(ww$value, fromLast = TRUE) + na.locf(ww$value))
mm <- ts_regular(ts_dts(mm))
mm$value <- 0.5 * (na.locf(mm$value, fromLast = TRUE) + na.locf(mm$value))
wd <- tempdisagg::td(ww ~ dd, method = "fast", conversion = "mean")
wd <- stats::predict(wd)
mwd <- tempdisagg::td(mm ~ wd, method = "fast", conversion = "mean")
mwd <- stats::predict(mwd)
as_tibble(mwd)
}
rmarkdown::render("vignettes/ifwtrends-intro.Rmd")
#'
#' factorR2(series, factors, plot = T)
#' }
#' @import tibble ggplot2 magrittr
#' @importFrom dplyr bind_rows
#' @importFrom dplyr bind_cols
#' @importFrom tidyr pivot_longer
#' @importFrom stringr str_c
#' @importFrom stats lm
#' @export
factorR2 <- function(series, factors, plot = F) {
stopifnot("series must contain leading time column" = class(series[[1]]) == "Date")
stopifnot("factors must contain leading time column" = class(factors[[1]]) == "Date")
R2 <- vector("list", length = (dim(series)[2] - 1))
# Helper to get the R2
f <- function(series) {
s <- summary(lm(factors[-1][[i]] ~ series))
s$r.squared
}
# Apply the helper function throughout both dfs
for (i in seq_along(factors[-1])) {
R2[[i]] <- apply(series[-1], 2, f)
}
# Combine the results
res <- bind_cols(
tibble(factors = str_c("PC", 1:length(factors[-1]))),
bind_rows(R2)
)
if (!plot) {
# Plot is not displayed
return(res)
} else {
# Conversion to long tibble for creating a ggplot
pcomp <- pivot_longer(factors, -date, names_to = "series", values_to = "value")
series <- pivot_longer(series, -date, names_to = "series", values_to = "value")
r2 <- pivot_longer(res, -factors, names_to = "series", values_to = "R2")
# ggplot barplot
plt <- r2 %>%
# filter(factors == "PC1") %>%
ggplot(aes(x = series, y = R2)) +
geom_bar(stat = "identity") +
facet_wrap(~factors, ncol = 1) +
theme(
axis.title.x = element_blank(),
axis.text.x = element_text(angle = 60, size = 6, vjust = 1, hjust = 1)
) +
labs(title = "R squared of the regression on different principal components") +
scale_y_continuous(breaks = c(0, 0.5, 1))
return(list(res = res, plot = plt))
}
}
rmarkdown::render("vignettes/ifwtrends-intro.Rmd")
#'@param fun Funktion, die auf die rollende Zeitreihe angewendet werden soll.
#'@param ... Zusaetzliche Parameter, die an die Funktion in fun weitergegeben werden
#'@return Monatliche Tabelle mit pca in jeder Spalte. Je Spalte wird ein neuer Monat hinzugenommen.
#'
#'@examples \dontrun{
#'roll(keyword = c("ikea", "saturn"), start_period = "2018-01-01", end = "2020-01-01")
#'}
#'@importFrom stringr str_c
#'@importFrom trendecon ts_gtrends
#'@export
roll <- function(keyword = NA,
category = 0,
geo = "DE",
start_series = "2006-01-01",
start_period = "2014-01-01",
end = Sys.Date(),
fun = trendecon::ts_gtrends,
...){
period <-  seq.Date(as.Date(start_period), as.Date(end), by = "month")
dates <- seq.Date(as.Date(start_series), as.Date(end), by = "month")
n <- length(dates)
f <- function(d) fun(keyword = keyword,
category = category,
geo = geo,
time = stringr::str_c(start_series," ", d),
...)
tl <- lapply(period, f)
return(tl)
}
rmarkdown::render("vignettes/ifwtrends-intro.Rmd")
filter(gtrendsR::categories, id %in% c(203, 206, 179, 1003, 1004, 208, 1010, 1011))
r_list <- readRDS("data/travel.rds")
rmarkdown::render("vignettes/ifwtrends-intro.Rmd")
r_list <- readRDS("anxiety.rds")
vdax<- readxl::read_xlsx("vdax.xlsx") %>%
transmute(time = floor_date(as.Date(Name), "month"), value = as.numeric(`VDAX-NEW VOLATILITY INDEX - PRICE INDEX`))
dat <- vdax %>%
filter(time >= min(first(r_list)$time))
forecast_m(r_list, dat, fd = F)$forec %>%
left_join(dat, by = "time") %>%
pivot_longer(cols = -time, names_to = "id", values_to = "value") %>%
ggplot(aes(x=  time, y = value, color = id)) +
geom_line()
rmarkdown::render("vignettes/ifwtrends-intro.Rmd")
